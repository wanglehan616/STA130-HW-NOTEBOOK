{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732e80ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Explanation of Simple Linear Regression Model\n",
    "\n",
    "A **Simple Linear Regression (SLR)** model is a statistical method used to understand the relationship between two variables: one predictor (or independent variable) and one outcome (or dependent variable). The model is expressed mathematically as:\n",
    "\n",
    "Y = \\beta_0 + \\beta_1 X + \\epsilon\n",
    "\n",
    "Where:\n",
    "- Y is the outcome variable (dependent variable).\n",
    "- X is the predictor variable (independent variable).\n",
    "- (\\beta_0\\) is the intercept, which represents the value of \\(Y\\) when \\(X = 0\\).\n",
    "- (\\epsilon\\) is the error term (or noise), which accounts for the variability in \\(Y\\) that is not explained by \\(X\\).\n",
    "\n",
    "The error term is assumed to be a random variable that is drawn from a normal distribution with mean 0 and some standard deviation \\(\\sigma\\) (i.e., \\(\\epsilon \\sim N(0, \\sigma^2)\\)).\n",
    "\n",
    "### Statistical Interpretation:\n",
    "The Simple Linear Regression model assumes that for each value of \\(X\\), the corresponding \\(Y\\) is drawn from a normal distribution centered at \\(\\beta_0 + \\beta_1 X\\), with a standard deviation \\(\\sigma\\). This error term represents random fluctuations or \"noise\" that we cannot predict or control, but it is assumed to be normally distributed.\n",
    "\n",
    "### Simulation with Python (Using `numpy` and `scipy.stats`)\n",
    "\n",
    "To demonstrate how the Simple Linear Regression model works, we can simulate data for \\(X\\) and \\(Y\\) based on an arbitrary choice of parameters (\\(\\beta_0\\), \\(\\beta_1\\), and \\(\\sigma\\)). We'll also generate random error terms from a normal distribution.\n",
    "\n",
    "### Python Code Example\n",
    "\n",
    "python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define parameters\n",
    "n = 100  # Number of data points\n",
    "beta0 = 3  # Intercept\n",
    "beta1 = 2  # Slope\n",
    "sigma = 1  # Standard deviation of error\n",
    "\n",
    "# Generate random predictor values (X) from a uniform distribution\n",
    "X = uniform.rvs(loc=0, scale=10, size=n)\n",
    "\n",
    "# Generate error terms (epsilon) from a normal distribution\n",
    "epsilon = np.random.normal(0, sigma, n)\n",
    "\n",
    "# Compute the outcome variable (Y) using the linear model: Y = beta0 + beta1 * X + epsilon\n",
    "Y = beta0 + beta1 * X + epsilon\n",
    "\n",
    "# Create the plot using Plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add the data points (X, Y)\n",
    "fig.add_trace(go.Scatter(x=X, y=Y, mode='markers', name='Data'))\n",
    "\n",
    "# Add the theoretical regression line (without noise)\n",
    "X_line = np.linspace(0, 10, 100)\n",
    "Y_line = beta0 + beta1 * X_line\n",
    "fig.add_trace(go.Scatter(x=X_line, y=Y_line, mode='lines', name='Theoretical Line', line=dict(color='red')))\n",
    "\n",
    "# Customize the plot\n",
    "fig.update_layout\n",
    "    (title=\"Simple Linear Regression - Y vs. X with Noise\",\n",
    "    xaxis_title=\"X\",\n",
    "    yaxis_title=\"Y\",\n",
    "    template=\"plotly_white\")\n",
    "\n",
    "### Explanation of the Code:\n",
    "\n",
    "1. Random Variables:\n",
    "   X is the predictor variable, generated randomly from a uniform distribution between 0 and 10.\n",
    "   epsilon` represents the error term, sampled from a normal distribution with mean 0 and standard deviation \\(\\sigma = 1\\).\n",
    "   \n",
    "2. Outcome Variable (Y):\n",
    "   The outcome variable \\(Y\\) is generated by plugging \\(X\\) and the error term \\(\\epsilon\\) into the Simple Linear Regression equation: \\(Y = \\beta_0 + \\beta_1 X + \\epsilon\\).\n",
    "\n",
    "3. Plotting:\n",
    "   The data points are plotted as markers.\n",
    "   The theoretical regression line (without noise) is also plotted in red, showing the underlying relationship defined by \\(Y = \\beta_0 + \\beta_1 X\\).\n",
    "\n",
    "### Expected Output:\n",
    "The plot should show a scatter of data points that follow the red regression line with some random noise (i.e., the points should scatter around the line, reflecting the variability in \\(Y\\) due to the error term).\n",
    "\n",
    "### Summary:\n",
    "This example simulates data based on a theoretical Simple Linear Regression model with noise. It illustrates how the predictor variable \\(X\\) is used to generate an outcome variable \\(Y\\), while random error is added to reflect real-world variability. The theoretical regression line shows the expected relationship between \\(X\\) and \\(Y\\) without noise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5d700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simple Linear Regression Fitting with `statsmodels` and Visualization in Plotly\n",
    "\n",
    "We will simulate data using the **Simple Linear Regression model** as we did previously, but this time, we will use the `statsmodels` library to fit the model and visualize the results.\n",
    "\n",
    "Let’s walk through the steps:\n",
    "\n",
    "### Step-by-Step Explanation:\n",
    "\n",
    "1. **Importing the required libraries:**\n",
    "    - `statsmodels.formula.api as smf`: This is part of the **`statsmodels`** library, which provides tools for statistical modeling. `smf` stands for **statsmodels formula API**, and it allows you to define and fit statistical models using formulas (similar to R syntax).\n",
    "    - `plotly.express as px`: This is a plotting library that makes it easy to create interactive plots.\n",
    "\n",
    "2. **What does `smf.ols(\"Y ~ x\", data=df)` do?**\n",
    "   - This line specifies an **Ordinary Least Squares (OLS)** regression model using the formula `Y ~ x`, where `Y` is the dependent variable and `x` is the independent variable. It takes the `df` dataframe as the data source and sets up the regression model for fitting.\n",
    "\n",
    "3. **What does `fitted_model = model_data_specification.fit()` do?**\n",
    "   - This fits the model (i.e., it finds the best-fitting line using the data) by estimating the coefficients (intercept and slope). This step applies the Ordinary Least Squares method to find the model parameters.\n",
    "\n",
    "4. **What does `fitted_model.summary()` provide?**\n",
    "   - This gives a detailed summary of the fitted model, including information about the coefficients, goodness of fit, and statistical significance of the variables. The summary includes things like the **R-squared**, **F-statistic**, and the p-values for the coefficients.\n",
    "\n",
    "5. **What does `fitted_model.summary().tables[1]` provide?**\n",
    "   - This provides the **coefficient table** from the model summary, which includes the estimated parameters (intercept and slope), standard errors, t-statistics, and p-values for each coefficient.\n",
    "\n",
    "6. **What does `fitted_model.params` provide?**\n",
    "   - This gives a **pandas series** with the estimated coefficients (intercept and slope) of the regression model.\n",
    "\n",
    "7. **What does `fitted_model.params.values` provide?**\n",
    "   - This gives the **values** of the estimated coefficients in an array format. It’s a simpler way to access just the numerical values without the labels.\n",
    "\n",
    "8. **What does `fitted_model.rsquared` provide?**\n",
    "   - This gives the **R-squared** value, which measures how well the regression model fits the data. It is the proportion of the variance in the dependent variable (`Y`) that is explained by the independent variable (`x`).\n",
    "\n",
    "### Python Code Example:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define parameters\n",
    "n = 100  # Number of data points\n",
    "beta0 = 3  # Intercept\n",
    "beta1 = 2  # Slope\n",
    "sigma = 1  # Standard deviation of error\n",
    "\n",
    "# Generate random predictor values (X) from a uniform distribution\n",
    "X = uniform.rvs(loc=0, scale=10, size=n)\n",
    "\n",
    "# Generate error terms (epsilon) from a normal distribution\n",
    "epsilon = np.random.normal(0, sigma, n)\n",
    "\n",
    "# Compute the outcome variable (Y) using the linear model: Y = beta0 + beta1 * X + epsilon\n",
    "Y = beta0 + beta1 * X + epsilon\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df = pd.DataFrame({'x': X, 'Y': Y})\n",
    "\n",
    "# 1. Fit the Simple Linear Regression model\n",
    "model_data_specification = smf.ols(\"Y ~ x\", data=df)  # What is this for? (Answer: Defines the regression model)\n",
    "fitted_model = model_data_specification.fit()  # What is this for? (Answer: Fits the model)\n",
    "\n",
    "# 2. Output of the fitted model\n",
    "print(fitted_model.summary())  # Simple explanation of summary output\n",
    "\n",
    "# 3. Coefficient table (includes parameter estimates, standard errors, t-values, and p-values)\n",
    "print(fitted_model.summary().tables[1])  # Simple explanation of the coefficient table\n",
    "\n",
    "# 4. Model parameters (intercept and slope)\n",
    "print(fitted_model.params)  # What does this provide? (Answer: Estimated intercept and slope)\n",
    "\n",
    "# 5. Model parameters as an array (values only)\n",
    "print(fitted_model.params.values)  # What does this provide? (Answer: Just the numerical values for intercept and slope)\n",
    "\n",
    "# 6. R-squared value (Goodness of fit)\n",
    "print(fitted_model.rsquared)  # Simple explanation of R-squared (Answer: Proportion of variance explained)\n",
    "\n",
    "# 7. Visualize the data and the fitted model\n",
    "df['Data'] = 'Data'  # Adding a dummy column for legend labeling\n",
    "\n",
    "# Create the plot\n",
    "fig = px.scatter(df, x='x', y='Y', color='Data', title='Simple Linear Regression: Y vs. x')\n",
    "\n",
    "# Add the fitted trendline to the plot (blue line)\n",
    "fig.add_scatter(x=df['x'], y=fitted_model.fittedvalues, \n",
    "                line=dict(color='blue'), name=\"OLS Trendline\")\n",
    "\n",
    "# Show the plot\n",
    "fig.show(renderer=\"png\")  # Use `fig.show()` for Jupyter notebooks or `fig.show(renderer=\"png\")` for GitHub/MarkUs submissions\n",
    "```\n",
    "\n",
    "### Explanation of the Code:\n",
    "\n",
    "1. **Simulating the data:**\n",
    "   - We first simulate `X` (predictor) values using a uniform distribution.\n",
    "   - Then we generate random errors (epsilon) from a normal distribution.\n",
    "   - Finally, we compute `Y` (the outcome variable) using the linear regression equation.\n",
    "\n",
    "2. **Fitting the Model:**\n",
    "   - We create the model using `smf.ols(\"Y ~ x\", data=df)`, specifying that `Y` is modeled as a function of `x`.\n",
    "   - The model is fitted using `fit()`, and the fitted model object contains all the statistics related to the regression.\n",
    "\n",
    "3. **Model Summary and Output:**\n",
    "   - We display the full summary of the fitted model using `fitted_model.summary()`, which includes information such as coefficients, t-values, p-values, and R-squared.\n",
    "   - `fitted_model.summary().tables[1]` gives us the detailed coefficient table with the estimates of the intercept and slope.\n",
    "   - We use `fitted_model.params` to access the model's parameters directly, and `fitted_model.rsquared` provides the R-squared value.\n",
    "\n",
    "4. **Visualization:**\n",
    "   - The scatter plot is created using `plotly.express` with the data points.\n",
    "   - The fitted regression line is added using `fitted_model.fittedvalues` to plot the predicted values of `Y` for each `X`.\n",
    "   - The `fig.show()` function displays the interactive plot.\n",
    "\n",
    "### Expected Output:\n",
    "\n",
    "- The plot will display the **data points** along with the **OLS trendline** (fitted regression line) in blue. This shows the relationship between the predictor variable (`X`) and the outcome variable (`Y`).\n",
    "- The printed summary will provide the details of the model's performance and the estimated coefficients.\n",
    "\n",
    "### Summary of Key Concepts:\n",
    "\n",
    "1. **`smf.ols(\"Y ~ x\", data=df)`**: Specifies the regression model using a formula syntax where `Y` is predicted by `x`.\n",
    "2. **`fitted_model.summary()`**: Provides a detailed statistical summary of the model, including coefficients and significance.\n",
    "3. **`fitted_model.params`**: Returns the coefficients (intercept and slope) of the regression.\n",
    "4. **`fitted_model.rsquared`**: Gives the R-squared value, indicating how well the model explains the variability in the data.\n",
    "5. **Plotting**: The regression line is visualized alongside the data points to show how the fitted model fits the data.\n",
    "\n",
    "This process demonstrates how to simulate data, fit a linear regression model, and visualize the results in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0499ccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Understanding the Difference Between the Two Lines: Theoretical Line vs. Fitted Line\n",
    "\n",
    "In this part of the question, we will add both the **theoretical regression line** (from the model in **Question 1**) and the **fitted regression line** (from the model in **Question 2**) to the plot and examine the differences.\n",
    "\n",
    "#### Theoretical Regression Line:\n",
    "The theoretical regression line is based on the equation:\n",
    "\n",
    "\\[\n",
    "Y = \\beta_0 + \\beta_1 X\n",
    "\\]\n",
    "\n",
    "This line is **deterministic**: for each value of \\(X\\), we know exactly what \\(Y\\) should be, assuming no error term. The theoretical line represents the **underlying relationship** between \\(X\\) and \\(Y\\) as we would expect it to be if there were no random variation or noise in the data.\n",
    "\n",
    "#### Fitted Regression Line:\n",
    "The fitted regression line, on the other hand, is determined by fitting the **Simple Linear Regression model** to the simulated data. This line represents the best guess at the relationship between \\(X\\) and \\(Y\\), accounting for the error terms and random fluctuations in the data. The fitted line minimizes the sum of squared residuals, or the distance between the observed data points and the predicted values of \\(Y\\).\n",
    "\n",
    "The fitted line can differ from the theoretical line because of **random sampling variation** (due to the error term in the simulation). In real-world data, there is always some noise, and the model is not perfect. The fitted regression line represents the line that best fits the observed data **as a whole**, while the theoretical line represents the expected values **without any noise**.\n",
    "\n",
    "### Adding the Theoretical Line to the Plot and Explanation\n",
    "\n",
    "We will modify the plot from **Question 2** to add the **theoretical regression line** (based on \\(\\beta_0\\) and \\(\\beta_1\\)) and visually compare it with the **fitted line** from the regression model. This will allow us to clearly see the difference between the two.\n",
    "\n",
    "### Updated Python Code:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define parameters\n",
    "n = 100  # Number of data points\n",
    "beta0 = 3  # Intercept\n",
    "beta1 = 2  # Slope\n",
    "sigma = 1  # Standard deviation of error\n",
    "\n",
    "# Generate random predictor values (X) from a uniform distribution\n",
    "X = uniform.rvs(loc=0, scale=10, size=n)\n",
    "\n",
    "# Generate error terms (epsilon) from a normal distribution\n",
    "epsilon = np.random.normal(0, sigma, n)\n",
    "\n",
    "# Compute the outcome variable (Y) using the linear model: Y = beta0 + beta1 * X + epsilon\n",
    "Y = beta0 + beta1 * X + epsilon\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df = pd.DataFrame({'x': X, 'Y': Y})\n",
    "\n",
    "# 1. Fit the Simple Linear Regression model\n",
    "model_data_specification = smf.ols(\"Y ~ x\", data=df)\n",
    "fitted_model = model_data_specification.fit()\n",
    "\n",
    "# 2. Visualize the data and the fitted model\n",
    "df['Data'] = 'Data'  # Adding a dummy column for legend labeling\n",
    "\n",
    "# Create the plot\n",
    "fig = px.scatter(df, x='x', y='Y', color='Data', title='Simple Linear Regression: Y vs. x')\n",
    "\n",
    "# Add the fitted trendline to the plot (blue line)\n",
    "fig.add_scatter(x=df['x'], y=fitted_model.fittedvalues, \n",
    "                line=dict(color='blue'), name=\"OLS Trendline\")\n",
    "\n",
    "# 3. Add the theoretical regression line (orange dotted line)\n",
    "x_range = np.array([df['x'].min(), df['x'].max()])\n",
    "y_line = beta0 + beta1 * x_range\n",
    "fig.add_scatter(x=x_range, y=y_line, mode='lines',\n",
    "                name=str(beta0)+' + '+str(beta1)+' * x', \n",
    "                line=dict(dash='dot', color='orange'))\n",
    "\n",
    "# Show the plot\n",
    "fig.show(renderer=\"png\")  # Use `fig.show()` for Jupyter notebooks or `fig.show(renderer=\"png\")` for GitHub/MarkUs submissions\n",
    "```\n",
    "\n",
    "### What is Happening in the Code:\n",
    "\n",
    "- **Theoretical Regression Line (Orange Dotted Line):**\n",
    "  - We calculate the values of \\(Y\\) using the formula \\(Y = \\beta_0 + \\beta_1 X\\) for a given range of \\(X\\) values, which gives us the theoretical line that represents the true underlying relationship between \\(X\\) and \\(Y\\) without any noise. This line is **deterministic** and should be the same each time we simulate the data with the same \\(\\beta_0\\) and \\(\\beta_1\\).\n",
    "\n",
    "- **Fitted Regression Line (Blue Line):**\n",
    "  - The fitted regression line is created by fitting an OLS model to the data and then plotting the predicted values (the fitted values). This line represents the best fit given the **observed data**, which includes random variation due to the error term. The fitted line **may differ slightly** from the theoretical line due to the noise (random sampling variation).\n",
    "\n",
    "### Explanation of the Difference Between the Two Lines:\n",
    "\n",
    "- **Theoretical Line (Orange, Dotted):**\n",
    "  - This is the \"true\" relationship between \\(X\\) and \\(Y\\) without any random variation or noise. The orange dotted line reflects the deterministic equation: \\(Y = \\beta_0 + \\beta_1 X\\). It’s consistent across simulations as it is based purely on the parameters \\(\\beta_0\\) and \\(\\beta_1\\).\n",
    "\n",
    "- **Fitted Line (Blue, Solid):**\n",
    "  - The fitted line comes from the **actual simulated data** and reflects the estimated relationship between \\(X\\) and \\(Y\\), based on observed values. Because the data includes noise (random errors), the fitted line can differ from the theoretical line, even if the true relationship between \\(X\\) and \\(Y\\) is the same across different simulations.\n",
    "  - The **fitted line** is the result of applying the **least squares method**, which minimizes the sum of squared differences between the observed values and the predicted values. This means that while the fitted line represents the best fit for the observed data, it’s an estimate of the true underlying relationship, and will vary from simulation to simulation due to random sampling variation.\n",
    "\n",
    "#### Summary of the Key Differences:\n",
    "\n",
    "1. **Theoretical Line (Orange)** is based purely on the true values of \\(\\beta_0\\) and \\(\\beta_1\\), without any error. It is deterministic and would be the same for any dataset generated under the same assumptions.\n",
    "   \n",
    "2. **Fitted Line (Blue)** is based on the observed data, which includes random error. It is the best fit for the observed data but can vary across different simulated datasets due to the randomness inherent in the error term.\n",
    "\n",
    "### What This Demonstrates:\n",
    "\n",
    "- **Sampling Variation**: The difference between the two lines visually demonstrates the effect of **sampling variation** on the fitted regression model. The fitted line fluctuates around the theoretical line due to the presence of random error in the data. This shows how noise in real-world data leads to deviations from the theoretical \"true\" relationship.\n",
    "  \n",
    "- **Model Estimation**: It also demonstrates that while the fitted regression line may be close to the theoretical line, it is still an estimate—**the best estimate based on the data**. As we generate different datasets from the same underlying model, the fitted lines will vary slightly due to the randomness in the errors.\n",
    "\n",
    "### Conclusion:\n",
    "By comparing these two lines, you can see the impact of **random sampling variation** on the regression model. The **fitted regression line** (blue) represents the relationship based on observed data, while the **theoretical regression line** (orange) shows the idealized relationship without any noise. This is an essential distinction when interpreting real-world data and regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758145d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Understanding How `fitted_model.fittedvalues` Are Derived\n",
    "\n",
    "In this question, you're asked to explain how the predicted values (or fitted values) from the Simple Linear Regression model, specifically from `fitted_model.fittedvalues`, are derived and how they relate to the model coefficients displayed in `fitted_model.summary().tables[1]`, which includes `fitted_model.params` or `fitted_model.params.values`.\n",
    "\n",
    "#### Theoretical Model vs. Fitted Model\n",
    "\n",
    "Recall that the **theoretical model** for a simple linear regression is expressed as:\n",
    "\n",
    "\\[\n",
    "Y = \\beta_0 + \\beta_1 \\cdot X\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( Y \\) is the outcome variable (dependent variable).\n",
    "- \\( X \\) is the predictor variable (independent variable).\n",
    "- \\( \\beta_0 \\) is the **intercept** of the regression line (the value of \\( Y \\) when \\( X = 0 \\)).\n",
    "- \\( \\beta_1 \\) is the **slope** of the regression line (the rate of change of \\( Y \\) as \\( X \\) changes).\n",
    "\n",
    "In a **fitted regression model**, we estimate the values of \\( \\beta_0 \\) and \\( \\beta_1 \\) from the data, which is different from the theoretical model where these coefficients are assumed to be known.\n",
    "\n",
    "The **fitted regression model** predicts the values of \\( Y \\) for each observed value of \\( X \\), based on the estimated coefficients \\( \\hat{\\beta}_0 \\) (estimated intercept) and \\( \\hat{\\beta}_1 \\) (estimated slope).\n",
    "\n",
    "#### How the Predicted Values (`fitted_model.fittedvalues`) Are Derived\n",
    "\n",
    "The predicted (or fitted) values are calculated using the estimated model coefficients, which are derived from the regression fit. Here’s the detailed breakdown:\n",
    "\n",
    "1. **Fitting the Model (Estimating the Coefficients):**\n",
    "   When you call `fitted_model = model_data_specification.fit()`, the `smf.ols()` method applies the **Ordinary Least Squares (OLS)** method to find the best-fitting line. It does this by minimizing the sum of the squared residuals (the differences between the observed values and the predicted values of \\( Y \\)).\n",
    "\n",
    "   This results in the estimated coefficients:\n",
    "   - \\( \\hat{\\beta}_0 \\) (the intercept)\n",
    "   - \\( \\hat{\\beta}_1 \\) (the slope)\n",
    "\n",
    "   These values are stored in `fitted_model.params`.\n",
    "\n",
    "2. **Formula for Fitted Values:**\n",
    "   After the model is fitted, we can predict the values of \\( Y \\) (denoted as \\( \\hat{Y} \\)) for each value of \\( X \\) in the dataset using the formula:\n",
    "\n",
    "   \\[\n",
    "   \\hat{Y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\cdot X_i\n",
    "   \\]\n",
    "\n",
    "   Where:\n",
    "   - \\( \\hat{Y}_i \\) is the fitted value for the \\( i \\)-th observation.\n",
    "   - \\( \\hat{\\beta}_0 \\) is the estimated intercept.\n",
    "   - \\( \\hat{\\beta}_1 \\) is the estimated slope.\n",
    "   - \\( X_i \\) is the \\( i \\)-th value of the predictor variable \\( X \\).\n",
    "\n",
    "   The values of \\( \\hat{Y}_i \\) are calculated for each value of \\( X_i \\) in the dataset, and these are what we call **fitted values** or **predicted values**.\n",
    "\n",
    "3. **Accessing Fitted Values:**\n",
    "   - `fitted_model.fittedvalues` stores the predicted values \\( \\hat{Y}_i \\) for all observations in the dataset.\n",
    "   - These fitted values are the \"in-sample\" predictions, meaning they are the values predicted by the model using the same data that was used to fit the model.\n",
    "\n",
    "#### Connection Between `fitted_model.fittedvalues` and `fitted_model.params`\n",
    "\n",
    "- **`fitted_model.params`**: This contains the estimated coefficients \\( \\hat{\\beta}_0 \\) and \\( \\hat{\\beta}_1 \\).\n",
    "  \n",
    "  ```python\n",
    "  print(fitted_model.params)\n",
    "  ```\n",
    "  \n",
    "  For example, this might output something like:\n",
    "  \n",
    "  ```\n",
    "  Intercept    3.09\n",
    "  Slope        1.92\n",
    "  dtype: float64\n",
    "  ```\n",
    "\n",
    "  Here, \\( \\hat{\\beta}_0 = 3.09 \\) and \\( \\hat{\\beta}_1 = 1.92 \\).\n",
    "\n",
    "- **`fitted_model.fittedvalues`**: Once you have the estimated coefficients, you can compute the fitted values for all observations in your dataset using the formula \\( \\hat{Y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\cdot X_i \\). These fitted values are exactly what `fitted_model.fittedvalues` contains.\n",
    "\n",
    "### Detailed Walkthrough:\n",
    "\n",
    "1. **Model Coefficients from `fitted_model.params`:**\n",
    "   Let's assume after fitting the model, we get the following coefficients:\n",
    "   \n",
    "   - \\( \\hat{\\beta}_0 = 3.09 \\)\n",
    "   - \\( \\hat{\\beta}_1 = 1.92 \\)\n",
    "   \n",
    "   These values represent the best estimates for the intercept and slope of the regression line, based on the observed data.\n",
    "\n",
    "2. **Predicted Values (`fitted_model.fittedvalues`):**\n",
    "   The fitted values (predictions) for each \\( X_i \\) in the dataset are calculated by plugging the values of \\( X \\) into the equation \\( Y = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\cdot X \\). For example, if \\( X_1 = 2.5 \\), the fitted value \\( \\hat{Y}_1 \\) would be:\n",
    "\n",
    "   \\[\n",
    "   \\hat{Y}_1 = 3.09 + 1.92 \\cdot 2.5 = 3.09 + 4.8 = 7.89\n",
    "   \\]\n",
    "\n",
    "   The fitted values are then computed for all data points.\n",
    "\n",
    "3. **`fitted_model.fittedvalues`:**\n",
    "   When you access `fitted_model.fittedvalues`, you are essentially accessing the predicted values \\( \\hat{Y}_i \\) for all observations, computed based on the estimated coefficients.\n",
    "\n",
    "#### Example: Let's Walk Through the Code\n",
    "\n",
    "Consider the following simplified example:\n",
    "\n",
    "```python\n",
    "# Simulating data again (just to be clear)\n",
    "X = np.array([1, 2, 3, 4, 5])\n",
    "Y = 3 + 2 * X + np.random.normal(0, 1, len(X))  # Y = 3 + 2X + noise\n",
    "\n",
    "df = pd.DataFrame({'x': X, 'Y': Y})\n",
    "\n",
    "# Fit the regression model\n",
    "model_data_specification = smf.ols(\"Y ~ x\", data=df)\n",
    "fitted_model = model_data_specification.fit()\n",
    "\n",
    "# Print the estimated coefficients\n",
    "print(fitted_model.params)\n",
    "\n",
    "# Output:\n",
    "# Intercept    3.04\n",
    "# Slope        2.05\n",
    "\n",
    "# Get the fitted values (predictions)\n",
    "print(fitted_model.fittedvalues)\n",
    "\n",
    "# Output:\n",
    "# 0    5.13\n",
    "# 1    7.18\n",
    "# 2    9.23\n",
    "# 3    11.28\n",
    "# 4    13.33\n",
    "# dtype: float64\n",
    "```\n",
    "\n",
    "Here’s how this works:\n",
    "- The estimated coefficients are \\( \\hat{\\beta}_0 = 3.04 \\) and \\( \\hat{\\beta}_1 = 2.05 \\).\n",
    "- The fitted values are computed by plugging each \\( X_i \\) into the regression equation:\n",
    "\n",
    "  hat{Y}_i = 3.04 + 2.05 \\cdot X_i\n",
    "\n",
    "For example:\n",
    "- For \\( X_0 = 1 \\), the fitted value \\( \\hat{Y}_0 \\) is:\n",
    "\n",
    "\n",
    "  hat{Y}_0 = 3.04 + 2.05 \\cdot 1 = 5.09\n",
    " \n",
    "- Similarly, for \\( X_1 = 2 \\), the fitted value \\( \\hat{Y}_1 \\) is:\n",
    "\n",
    "  hat{Y}_1 = 3.04 + 2.05 \\cdot 2 = 7.14\n",
    "  \n",
    "\n",
    "These fitted values are the values that are stored in `fitted_model.fittedvalues`.\n",
    "\n",
    "### Summary of Key Points:\n",
    "1. **Fitted values (`fitted_model.fittedvalues`)** are the predicted values for each data point in the dataset, based on the estimated regression coefficients.\n",
    "2. The **regression coefficients** (intercept and slope), which are stored in `fitted_model.params`, are estimated using OLS fitting.\n",
    "3. The predicted values are calculated using the formula \\( \\hat{Y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\cdot X_i \\).\n",
    "4. These fitted values are the \"in-sample predictions\" of the regression model, derived from the same data used to estimate the model.\n",
    "\n",
    "This is a demonstration of how the fitted values represent the best predictions for the dependent variable \\( Y \\) based on the fitted model and the given values of \\( X \\)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27b6f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "The **ordinary least squares (OLS)** method is used to estimate the best-fitting line in a simple linear regression model. This line is chosen based on the principle of minimizing the **sum of the squared residuals**, where residuals are the differences between the observed values of the outcome variable \\( Y \\) and the predicted values (fitted values) from the model.\n",
    "\n",
    "### Why \"Squares\"?\n",
    "\n",
    "The term \"squares\" refers to the fact that OLS minimizes the sum of **squared residuals**. Here's why:\n",
    "\n",
    "1. **Residuals**: These are the vertical distances between the observed data points and the fitted line. If we denote the residual for each data point \\( i \\) as:\n",
    "   \n",
    "   \\text{Residual}_i = Y_i - \\hat{Y}_i\n",
    "\n",
    "   where \\( Y_i \\) is the actual observed value, and \\( \\hat{Y}_i \\) is the predicted value based on the fitted line.\n",
    "\n",
    "2. **Squaring the residuals**: By squaring the residuals, we:\n",
    "   - Ensure that both positive and negative residuals contribute equally to the total error. Without squaring, positive and negative errors could cancel each other out.\n",
    "   - Emphasize larger errors, as squaring increases the weight of larger deviations.\n",
    "\n",
    "   The squared residuals for all points are summed to form the **sum of squared residuals (SSR)**:\n",
    "\n",
    "   SSR = \\sum_{i} (Y_i - \\hat{Y}_i)^2\n",
    "\n",
    "3. **Minimizing the sum of squared residuals**: OLS seeks to minimize this sum by adjusting the parameters (intercept and slope) of the regression line until the error between the predicted and observed values is as small as possible. This results in the best-fitting line.\n",
    "\n",
    "### Key Points:\n",
    "- The fitted line is chosen so that it minimizes the squared differences between the actual data points and the line itself. \n",
    "- **Squaring** the residuals helps to avoid cancellation of positive and negative errors and gives greater importance to larger deviations, which guides the fitting process towards a more accurate model.\n",
    "\n",
    "### Visualization Context:\n",
    "The code you've shared generates the following visualization:\n",
    "- **Blue Line (`trendline='ols'`)**: This is the regression line estimated by OLS, which represents the line that minimizes the squared residuals.\n",
    "- **Orange Line**: This is the true line used in the simulation (based on the specified values of \\( \\beta_0 \\) and \\( \\beta_1 \\)).\n",
    "- **Red Dashes**: These represent the **residuals**, or the vertical distances from each observed point to the corresponding predicted value (i.e., the blue line).\n",
    "\n",
    "In essence, the **OLS method** finds the line that best fits the data by adjusting the slope and intercept so that the sum of squared residuals is minimized. The residuals represent the differences between the observed data and the model's predictions, and the squaring ensures that larger discrepancies are penalized more heavily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9700823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Explanation of R-squared and Its Interpretation in Simple Linear Regression\n",
    "\n",
    "In the context of a **Simple Linear Regression (SLR)** model, **R-squared** (denoted as \\( R^2 \\)) is a statistical measure that indicates how well the regression model explains the variation in the outcome variable \\( Y \\). Let’s break down the given expressions and explain their significance:\n",
    "\n",
    "### The First Expression:\n",
    "\n",
    "1 - \\frac{\\sum_i (Y_i - \\hat{Y}_i)^2}{\\sum_i (Y_i - \\bar{Y})^2}\n",
    "\n",
    "Where:\n",
    "- \\( Y_i \\) are the observed values of the outcome variable \\( Y \\),\n",
    "- \\( \\hat{Y}_i \\) are the predicted values from the fitted model (i.e., `fitted_model.fittedvalues`),\n",
    "- \\( \\bar{Y} \\) is the mean of the observed values \\( Y \\),\n",
    "- The numerator \\( \\sum_i (Y_i - \\hat{Y}_i)^2 \\) is the **sum of squared residuals** (or **SSR**), which measures the unexplained variation in \\( Y \\),\n",
    "- The denominator \\( \\sum_i (Y_i - \\bar{Y})^2 \\) is the **total sum of squares** (or **TSS**), which measures the total variation in \\( Y \\) from its mean.\n",
    "\n",
    "### Interpretation of the First Expression:\n",
    "This expression calculates **R-squared** as the proportion of the total variation in \\( Y \\) that is explained by the regression model.\n",
    "\n",
    "- **Total variation** in \\( Y \\) is measured by \\( \\sum_i (Y_i - \\bar{Y})^2 \\), which is the total squared distance of the observed values from the mean of \\( Y \\).\n",
    "- **Explained variation** is the difference between the total variation and the unexplained variation, which is the **sum of squared residuals** \\( \\sum_i (Y_i - \\hat{Y}_i)^2 \\). The smaller the residuals, the better the model fits the data.\n",
    "\n",
    "So, **R-squared** is the fraction of the total variation in \\( Y \\) that is \"accounted for\" by the model (i.e., explained by the predicted values \\( \\hat{Y}_i \\)).\n",
    "\n",
    "R^2 = 1 - \\frac{\\text{SSR}}{\\text{TSS}}\n",
    "\n",
    "\n",
    "If \\( R^2 \\) is close to 1, it means that most of the variability in \\( Y \\) is explained by the model, suggesting a good fit. If \\( R^2 \\) is close to 0, it means the model does not explain much of the variability in \\( Y \\), indicating a poor fit.\n",
    "\n",
    "### `fitted_model.rsquared`:\n",
    "\n",
    "- The value of `fitted_model.rsquared` directly gives the **R-squared** value from the fitted regression model. It tells you the proportion of the variation in \\( Y \\) that is explained by the linear relationship between \\( X \\) and \\( Y \\).\n",
    "  \n",
    "  **Interpretation**: \n",
    "  - If \\( R^2 = 0.85 \\), this means that 85% of the variation in \\( Y \\) can be explained by the linear relationship with \\( X \\), and the remaining 15% is unexplained (due to factors not captured by the model, such as noise or other unobserved variables).\n",
    "\n",
    "### The Two `np.corrcoef` Expressions:\n",
    "\n",
    "1. **`np.corrcoef(Y, fitted_model.fittedvalues)[0, 1] ** 2`**:\n",
    "   \n",
    "   This expression computes the **correlation coefficient** between the observed values \\( Y \\) and the fitted values \\( \\hat{Y} \\). Squaring the correlation coefficient gives the **R-squared** value. In fact, the **correlation coefficient** between \\( Y \\) and \\( \\hat{Y} \\) is equivalent to the square root of **R-squared**.\n",
    "\n",
    "   - The correlation between \\( Y \\) and \\( \\hat{Y} \\) tells us how closely the observed values align with the predicted values. If the correlation is high (close to 1), the fitted model is a good predictor of \\( Y \\).\n",
    "\n",
    "   **Interpretation**: \n",
    "   - This gives the **proportion of variation** in \\( Y \\) that is explained by the fitted model, just as \\( R^2 \\) does.\n",
    "\n",
    "2. **`np.corrcoef(Y, x)[0, 1] ** 2`**:\n",
    "\n",
    "   This expression calculates the **correlation coefficient** between the observed values \\( Y \\) and the predictor variable \\( X \\), and then squares it. This squared value represents the **proportion of variation** in \\( Y \\) that is linearly related to \\( X \\).\n",
    "\n",
    "   **Interpretation**: \n",
    "   - This expression gives us the **strength of the linear relationship** between \\( X \\) and \\( Y \\). A value close to 1 suggests that \\( X \\) is a strong predictor of \\( Y \\), while a value close to 0 indicates that \\( X \\) does not explain much of the variation in \\( Y \\).\n",
    "\n",
    "### Summary of the Key Concepts:\n",
    "\n",
    "- **R-squared** (from the first expression and `fitted_model.rsquared`) tells you how well the fitted model (predicted values) explains the variation in the observed outcome \\( Y \\). It is a proportion, and the closer it is to 1, the better the model explains the variability in \\( Y \\).\n",
    "  \n",
    "- The **correlation coefficient** between \\( Y \\) and the fitted values \\( \\hat{Y} \\), when squared, gives the same value as **R-squared**, showing the proportion of the variation in \\( Y \\) explained by the model.\n",
    "\n",
    "- **`np.corrcoef(Y, x)[0, 1] ** 2`** gives the proportion of the variation in \\( Y \\) that is linearly related to \\( X \\). It is a measure of how strongly the predictor \\( X \\) is related to the outcome \\( Y \\).\n",
    "\n",
    "Thus, R-squared provides a direct measure of **how accurate the model is** in explaining the variation in \\( Y \\), and the squared correlation between \\( Y \\) and the fitted values shows how much of that variation is captured by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83381d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "The Simple Linear Regression (SLR) model is built on several assumptions that need to be met for the results to be valid. These assumptions include:\n",
    "\n",
    "1. **Linearity**: The relationship between the predictor variable \\( X \\) and the outcome variable \\( Y \\) is assumed to be linear.\n",
    "2. **Independence of Errors**: The residuals (errors) are assumed to be independent of each other.\n",
    "3. **Homoscedasticity**: The residuals are assumed to have constant variance across all levels of \\( X \\).\n",
    "4. **Normality of Errors**: The residuals are assumed to be normally distributed.\n",
    "\n",
    "Let's now consider the example data you've provided (fertilizer amount and crop yield) and identify a couple of potential issues with the assumptions in the context of this dataset.\n",
    "\n",
    "### Assumption 1: **Linearity**\n",
    "- The Simple Linear Regression model assumes that the relationship between the independent variable \\( X \\) (Amount of Fertilizer) and the dependent variable \\( Y \\) (Crop Yield) is **linear**. \n",
    "- From the scatter plot (`fig1`), we can observe that while the relationship between fertilizer and crop yield appears to be somewhat increasing, the growth in crop yield seems to **accelerate** as fertilizer increases (i.e., a **curvilinear** relationship, possibly quadratic). This suggests that the linearity assumption might not hold well, as the relationship could be better represented by a non-linear model (for example, a quadratic model).\n",
    "- **Potential violation**: The data may exhibit non-linear trends, so a linear regression model might not fit the data well, and fitting a line may not capture the true underlying pattern.\n",
    "\n",
    "### Assumption 2: **Homoscedasticity** (Constant Variance of Residuals)\n",
    "- The assumption of homoscedasticity means that the variance of the residuals should be constant across all levels of \\( X \\). In other words, as the independent variable changes, the spread (or variability) of the residuals should remain roughly the same.\n",
    "- The histogram of residuals (`fig2`) can give us some insights into the variance of residuals across different levels of \\( X \\). If you observe a pattern in the residuals (e.g., residuals becoming more spread out or more tightly clustered as the values of \\( X \\) increase), it would indicate that the variance of residuals is not constant, and the homoscedasticity assumption is violated.\n",
    "- **Potential violation**: Looking at the residual plot, there might be signs of **heteroscedasticity** (e.g., the residuals might fan out or contract as \\( X \\) increases). This suggests that the variability in crop yield increases as the amount of fertilizer increases, which violates the assumption of constant variance.\n",
    "\n",
    "### Assumption 3: **Independence of Errors**\n",
    "- The residuals should be independent of each other, meaning there should be no systematic pattern to the residuals. If there are patterns or correlations between residuals, this assumption is violated.\n",
    "- This assumption is hard to visualize directly from the plots you've shown (scatter plot and histogram), but it's something that could be checked using a **residual vs. time** plot or by examining the autocorrelation of residuals, especially in time series data.\n",
    "- **Potential violation**: If the data points are collected over time or in a way where one observation influences the next, residuals could exhibit autocorrelation. However, based on the data provided, we can't definitively assess this assumption without additional context, such as the ordering of observations.\n",
    "\n",
    "### Assumption 4: **Normality of Errors**\n",
    "- The residuals should be approximately normally distributed for valid hypothesis testing (e.g., for constructing confidence intervals or performing significance tests on the regression coefficients).\n",
    "- You can assess the normality of residuals visually by inspecting the **histogram** of residuals (`fig2`). If the residuals form a bell-shaped curve, this suggests that the normality assumption is met. If they are skewed or have heavy tails, the normality assumption may be violated.\n",
    "- **Potential violation**: Based on the histogram of residuals, if the distribution of residuals is **skewed** or shows **heavy tails**, it would indicate a deviation from normality. This would suggest that some non-normality in the errors could exist.\n",
    "\n",
    "### Summary of Potential Violations:\n",
    "\n",
    "- **Linearity**: The relationship between fertilizer and crop yield may not be strictly linear, potentially violating the assumption of linearity.\n",
    "- **Homoscedasticity**: The residuals might exhibit non-constant variance, violating the homoscedasticity assumption.\n",
    "- **Normality of Errors**: The histogram of residuals should be checked for normality; deviations from normality could affect the validity of the regression model.\n",
    "  \n",
    "In summary, based on this dataset, potential violations of the assumptions include non-linearity and heteroscedasticity. Both of these could influence the accuracy and reliability of the fitted model, suggesting that a more sophisticated model (e.g., quadratic regression or a model that accounts for changing variance) might be more appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8c9e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this task, you're working with a dataset from the \"Old Faithful\" geyser, which records the waiting time between eruptions (`waiting`) and the duration of the eruptions (`duration`). The provided code snippet demonstrates how to:\n",
    "\n",
    "1. **Plot a Simple Linear Regression (OLS) Trendline**: Using `plotly.express`, a scatter plot of the relationship between `waiting` time and `duration` is created. A Simple Linear Regression trendline is automatically added to this plot with the `trendline='ols'` argument.\n",
    "\n",
    "2. **Add a Smoothed LOWESS (Locally Weighted Scatterplot Smoothing) Trendline**: LOWESS is a non-parametric regression technique used to smooth out data. It creates a smoothed curve by fitting multiple local linear regressions. The parameter `frac` controls the bandwidth of the smoothing—higher values result in a smoother curve by considering more points, while lower values provide more local detail.\n",
    "\n",
    "### Key Components of the Code:\n",
    "\n",
    "1. **OLS Trendline**: \n",
    "   The code first generates a scatter plot with a simple linear regression (OLS) trendline. This is a parametric approach that fits a straight line to the data using the method of least squares (minimizing the sum of squared residuals). The OLS model assumes a linear relationship between `waiting` and `duration`.\n",
    "\n",
    "2. **LOWESS Trendline**:\n",
    "   The LOWESS trendline is added using `statsmodels.api.sm.nonparametric.lowess`. This method fits locally weighted regressions to smooth the data. The `frac` parameter determines the smoothness of the trendline. Smaller values of `frac` lead to a more locally sensitive fit, while larger values result in a smoother, less sensitive fit to fluctuations in the data.\n",
    "\n",
    "### Differences Between OLS and LOWESS:\n",
    "\n",
    "- **OLS (Ordinary Least Squares)**: Assumes a linear relationship between the variables, and fits the best straight line that minimizes the squared differences between observed values and the fitted values. It might not capture non-linear patterns well.\n",
    "  \n",
    "- **LOWESS**: A non-parametric method that does not assume any particular form for the relationship between the variables. It smooths the data locally and can capture non-linear trends in the data.\n",
    "\n",
    "### Visual Comparison:\n",
    "\n",
    "- The **OLS trendline** will appear as a straight line (if the relationship is linear) that fits the data using the least squares method.\n",
    "- The **LOWESS trendline** will appear as a curved line that adapts to local fluctuations in the data and is more flexible in capturing non-linear patterns.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "- The OLS trendline is a simple and interpretable method, but it assumes that the relationship between `waiting` and `duration` is linear. If the true relationship is more complex (non-linear), OLS might not capture the underlying structure of the data well.\n",
    "- The LOWESS trendline, on the other hand, provides a smoothed fit that can capture more complex patterns in the data without assuming a specific parametric form. However, the smoothness depends on the `frac` parameter, and a poorly chosen `frac` can either oversmooth or under-smooth the data.\n",
    "\n",
    "In this case, adding both the OLS and LOWESS trendlines gives you two perspectives: a simple linear relationship and a more flexible, smoothed fit that can adapt to any non-linearities in the data. The comparison between these two methods can provide insight into the true nature of the relationship between `waiting` time and `duration` for Old Faithful eruptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da01070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Null Hypothesis for Simple Linear Regression:\n",
    "\n",
    "In the context of Simple Linear Regression, the null hypothesis of \"no linear association (on average)\" can be stated in terms of the regression parameters as follows:\n",
    "\n",
    "- **Null Hypothesis (H₀)**: There is **no linear relationship** between the independent variable `waiting` (the time between eruptions) and the dependent variable `duration` (the duration of eruptions). Mathematically, this is expressed as:\n",
    "  \n",
    "  H_0: \\beta_1 = 0\n",
    "    \n",
    "  where \\(\\beta_1\\) is the slope of the regression line. If \\(\\beta_1 = 0\\), it means that for every unit increase in `waiting`, there is no expected change in the `duration` of the eruptions—i.e., the two variables are unrelated.\n",
    "\n",
    "- **Alternative Hypothesis (H₁)**: There is a **linear relationship** between `waiting` and `duration`. Mathematically, this is expressed as:\n",
    "  \n",
    "  H_1: \\beta_1 \\neq 0\n",
    "  \n",
    "  This suggests that the slope is not zero and that changes in the waiting time between eruptions are associated with changes in the eruption duration.\n",
    "\n",
    "### Using the Code to Evaluate the Hypothesis:\n",
    "\n",
    "The provided code uses **Ordinary Least Squares (OLS)** regression to estimate the relationship between the waiting time and the eruption duration. The **summary()** function from `statsmodels` gives us statistical results, including the estimated coefficients, their standard errors, and the p-value for testing the hypothesis that the slope \\(\\beta_1 = 0\\).\n",
    "\n",
    "Here's a breakdown of how the code helps:\n",
    "\n",
    "```python\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Load the Old Faithful dataset\n",
    "old_faithful = sns.load_dataset('geyser')\n",
    "\n",
    "# Specify the linear regression model\n",
    "linear_for_specification = 'duration ~ waiting'\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = smf.ols(linear_for_specification, data=old_faithful)\n",
    "fitted_model = model.fit()\n",
    "\n",
    "# View the regression results\n",
    "fitted_model.summary()\n",
    "```\n",
    "\n",
    "### Interpreting the `fitted_model.summary()` Output:\n",
    "\n",
    "The key result you want to focus on in this context is the **p-value** for the slope coefficient \\(\\beta_1\\), which is the coefficient for `waiting` in the regression output. Here's how to interpret it:\n",
    "\n",
    "- **p-value** for \\(\\beta_1\\): This value tells us whether we can reject the null hypothesis that \\(\\beta_1 = 0\\). The general threshold for significance is a p-value of **0.05** (though this can be adjusted depending on the context).\n",
    "  \n",
    "    - If **p-value ≤ 0.05**, we **reject the null hypothesis** and conclude that there is **evidence of a linear association** between `waiting` and `duration`.\n",
    "    - If **p-value > 0.05**, we **fail to reject the null hypothesis** and conclude that there is **insufficient evidence** to suggest a linear relationship between `waiting` and `duration`.\n",
    "\n",
    "### Interpreting Evidence Against the Null Hypothesis:\n",
    "\n",
    "Once you've obtained the p-value, you can interpret the evidence against the null hypothesis as follows:\n",
    "\n",
    "- **Very Strong Evidence (p-value < 0.001)**: The data strongly suggest a linear relationship.\n",
    "- **Strong Evidence (0.001 ≤ p-value < 0.01)**: The data provide strong evidence against the null hypothesis.\n",
    "- **Moderate Evidence (0.01 ≤ p-value < 0.05)**: The data provide moderate evidence against the null hypothesis.\n",
    "- **Weak Evidence (0.05 ≤ p-value < 0.10)**: There is weak evidence against the null hypothesis, but it is not conclusive.\n",
    "- **No Evidence (p-value ≥ 0.10)**: The data provide no significant evidence against the null hypothesis, meaning that the relationship could be due to random chance.\n",
    "\n",
    "### Example Interpretation:\n",
    "\n",
    "Assume that after running the code, you get the following output for the p-value of the slope coefficient \\(\\beta_1\\):\n",
    "\n",
    "```\n",
    "                            OLS Regression Results\n",
    "==============================================================================\n",
    "Dep. Variable:                duration   R-squared:                       0.142\n",
    "Model:                            OLS   Adj. R-squared:                  0.130\n",
    "Method:                 Least Squares   F-statistic:                     13.41\n",
    "Date:                Tue, 07 Nov 2024   Prob (F-statistic):           0.000365\n",
    "T-statistic:                  -3.64   P>|t|:                         0.0003\n",
    "==============================================================================\n",
    "```\n",
    "\n",
    "- **p-value = 0.0003** for the slope coefficient, which is much smaller than 0.05.\n",
    "- This indicates **very strong evidence against the null hypothesis**, meaning there is a statistically significant linear relationship between the `waiting` time and the `duration` of the eruptions.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "- Based on the p-value, we would **reject the null hypothesis** and conclude that there is strong evidence that the waiting time between eruptions is linearly associated with the duration of the eruptions in the Old Faithful dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a617d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "To address the question about whether there is evidence for a relationship between **duration** and **waiting** in the context of **short wait times** (i.e., waiting times less than 62, 64, or 66 minutes), we'll walk through the process of hypothesis testing with the given code, interpret the results, and then make conclusions based on the statistical output.\n",
    "\n",
    "### 1. **Setting Up the Problem:**\n",
    "\n",
    "The null hypothesis for this analysis remains the same as in the previous question:\n",
    "- **Null Hypothesis (H₀):** There is **no linear relationship** between the waiting time (`waiting`) and the eruption duration (`duration`). Mathematically, this can be expressed as:\n",
    "  \n",
    "  \\[\n",
    "  H_0: \\beta_1 = 0\n",
    "  \\]\n",
    "  \n",
    "  Where \\(\\beta_1\\) is the slope of the regression line. If \\(\\beta_1 = 0\\), it means the waiting time does not significantly affect the eruption duration.\n",
    "\n",
    "- **Alternative Hypothesis (H₁):** There **is a linear relationship** between waiting time and eruption duration, i.e., the slope \\(\\beta_1\\) is not equal to zero.\n",
    "\n",
    "### 2. **Hypothesis Testing Approach:**\n",
    "\n",
    "We will perform a **linear regression** using the subset of the data where the waiting time is less than the specified limit (62, 64, or 66 minutes). For each subset, we will check the p-value associated with the slope coefficient \\(\\beta_1\\) to assess the strength of the evidence against the null hypothesis.\n",
    "\n",
    "The p-value will help us determine whether the data provide enough evidence to reject the null hypothesis (i.e., suggest a linear relationship between waiting time and eruption duration).\n",
    "\n",
    "### 3. **Code Walkthrough and Statistical Output:**\n",
    "\n",
    "The code provided below fits an OLS regression model for the subset of data where the waiting time is less than the specified limit. The `smf.ols()` function fits the model, and the `summary().tables[1]` part extracts the p-value for the slope coefficient:\n",
    "\n",
    "```python\n",
    "import plotly.express as px\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "short_wait_limit = 62 # 64 # 66 #\n",
    "short_wait = old_faithful.waiting < short_wait_limit\n",
    "\n",
    "# Fit the linear regression model for short wait times\n",
    "print(smf.ols('duration ~ waiting', data=old_faithful[short_wait]).fit().summary().tables[1])\n",
    "\n",
    "# Create a scatter plot with a linear regression trendline\n",
    "fig = px.scatter(old_faithful[short_wait], x='waiting', y='duration', \n",
    "                 title=\"Old Faithful Geyser Eruptions for short wait times (<\"+str(short_wait_limit)+\")\", \n",
    "                 trendline='ols')\n",
    "\n",
    "fig.show()  # USE `fig.show(renderer=\"png\")` FOR ALL GitHub and MarkUs SUBMISSIONS\n",
    "```\n",
    "\n",
    "#### Steps in the Code:\n",
    "\n",
    "- `short_wait_limit = 62` (or 64 or 66) limits the data to waiting times below the specified value.\n",
    "- `short_wait = old_faithful.waiting < short_wait_limit` creates a mask to filter the data based on the waiting time.\n",
    "- `smf.ols('duration ~ waiting', data=old_faithful[short_wait]).fit().summary().tables[1]` performs an OLS regression and extracts the summary of the regression model.\n",
    "- `fig = px.scatter(...)` creates a scatter plot of the filtered data with the regression trendline.\n",
    "\n",
    "### 4. **Interpreting the Results:**\n",
    "\n",
    "In the regression output from `fitted_model.summary().tables[1]`, we are particularly interested in the **p-value** associated with the slope coefficient (`waiting`), which tests the null hypothesis that \\(\\beta_1 = 0\\).\n",
    "\n",
    "- **If the p-value ≤ 0.05**, we reject the null hypothesis and conclude that there is evidence of a linear relationship between `waiting` and `duration` for the subset of data with short wait times.\n",
    "- **If the p-value > 0.05**, we fail to reject the null hypothesis and conclude that there is no statistically significant linear relationship between `waiting` and `duration` in this subset.\n",
    "\n",
    "### 5. **Expected Output and Conclusion:**\n",
    "\n",
    "#### Example 1: `short_wait_limit = 62`\n",
    "\n",
    "You might get output similar to the following (hypothetical example):\n",
    "\n",
    "```\n",
    "==============================================================================\n",
    "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
    "------------------------------------------------------------------------------\n",
    "Intercept      55.2000      5.980      9.23      0.000      43.239      67.161\n",
    "waiting         0.1234      0.054      2.28      0.029       0.017       0.230\n",
    "==============================================================================\n",
    "```\n",
    "\n",
    "- The **p-value** for the `waiting` variable is 0.029, which is **less than 0.05**. Therefore, we **reject the null hypothesis** and conclude that there is evidence of a significant positive relationship between waiting time and eruption duration for waiting times less than 62 minutes.\n",
    "\n",
    "#### Example 2: `short_wait_limit = 64`\n",
    "\n",
    "You might get an output like this:\n",
    "\n",
    "```\n",
    "==============================================================================\n",
    "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
    "------------------------------------------------------------------------------\n",
    "Intercept      53.4000      6.210      8.60      0.000      41.042      65.758\n",
    "waiting         0.1050      0.072      1.46      0.165      -0.035       0.245\n",
    "==============================================================================\n",
    "```\n",
    "\n",
    "- The **p-value** for `waiting` is 0.165, which is **greater than 0.05**. Therefore, we **fail to reject the null hypothesis**, and there is **insufficient evidence** to suggest a linear relationship between waiting time and eruption duration for waiting times less than 64 minutes.\n",
    "\n",
    "#### Example 3: `short_wait_limit = 66`\n",
    "\n",
    "If the p-value is somewhere between the two extremes, say 0.03 or 0.10, the conclusion will depend on the value.\n",
    "\n",
    "### 6. **Conclusions:**\n",
    "\n",
    "- **For small short wait limits (e.g., 62 minutes)**, if the p-value is less than 0.05, you would conclude that there is a statistically significant relationship between waiting time and eruption duration.\n",
    "- **For slightly larger short wait limits (e.g., 64 or 66 minutes)**, the p-value might become larger, and you may fail to reject the null hypothesis, indicating that the relationship is not statistically significant for those subsets of data.\n",
    "\n",
    "This approach allows you to investigate the strength of the relationship between waiting time and eruption duration in different subsets of the Old Faithful Geyser dataset based on the waiting time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0250a5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "To address the task of visualizing the **bootstrapped sampling distribution of the fitted slope coefficients** and comparing it to the **null hypothesis assumption of \"no linear association\"** in the context of long wait times, we will break it down into two main parts: \n",
    "\n",
    "1. **Bootstrap Sampling of Slope Coefficients:**\n",
    "   - We'll create several bootstrapped samples from the data for long wait times and fit Simple Linear Regression models to each of these samples to get the distribution of the fitted slope coefficients.\n",
    "   \n",
    "2. **Simulating Data Under the Null Hypothesis of No Linear Association:**\n",
    "   - We'll simulate new datasets under the assumption that there is **no linear association** between waiting time and eruption duration, and fit Simple Linear Regression models to each simulated dataset to collect the sampling distribution of the fitted slope coefficients. This will allow us to estimate the p-value and confidence interval under the null hypothesis.\n",
    "\n",
    "### 1. **Code for Bootstrap Sampling Distribution of the Slope Coefficients**\n",
    "\n",
    "To create bootstrapped samples from the long wait times dataset and collect the slope coefficients, we will:\n",
    "\n",
    "- Use **resampling with replacement** to generate bootstrapped samples.\n",
    "- Fit a Simple Linear Regression model to each bootstrapped sample.\n",
    "- Collect the slope coefficients from each of the fitted models.\n",
    "\n",
    "Here is the code to perform these steps:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from scipy import stats\n",
    "\n",
    "# Define the long wait time limit and filter the dataset\n",
    "long_wait_limit = 71\n",
    "long_wait = old_faithful.waiting > long_wait_limit\n",
    "\n",
    "# Get the original dataset for long wait times\n",
    "long_wait_data = old_faithful[long_wait]\n",
    "\n",
    "# Bootstrap sampling of slope coefficients\n",
    "num_bootstrap_samples = 1000  # Number of bootstrap samples\n",
    "bootstrapped_slope_coefficients = []\n",
    "\n",
    "# Run the bootstrap process\n",
    "for _ in range(num_bootstrap_samples):\n",
    "    # Resample with replacement from the long wait times data\n",
    "    bootstrap_sample = long_wait_data.sample(n=len(long_wait_data), replace=True)\n",
    "    \n",
    "    # Fit the linear model to the bootstrap sample\n",
    "    model = smf.ols('duration ~ waiting', data=bootstrap_sample).fit()\n",
    "    \n",
    "    # Append the fitted slope coefficient to the list\n",
    "    bootstrapped_slope_coefficients.append(model.params[1])\n",
    "\n",
    "# Convert the list of coefficients to a NumPy array for easier analysis\n",
    "bootstrapped_slope_coefficients = np.array(bootstrapped_slope_coefficients)\n",
    "\n",
    "# Create a histogram to visualize the bootstrapped sampling distribution of the slope coefficients\n",
    "fig = px.histogram(x=bootstrapped_slope_coefficients, nbins=50, \n",
    "                   title='Bootstrapped Sampling Distribution of Slope Coefficients (Long Wait Times)',\n",
    "                   labels={'x': 'Slope Coefficient (waiting)'})\n",
    "fig.show()\n",
    "\n",
    "# Calculate the 95% confidence interval for the slope coefficients\n",
    "conf_interval = np.quantile(bootstrapped_slope_coefficients, [0.025, 0.975])\n",
    "print(f\"95% Bootstrapped Confidence Interval: {conf_interval}\")\n",
    "```\n",
    "\n",
    "### 2. **Simulating Data Under the Null Hypothesis**\n",
    "\n",
    "Under the null hypothesis of \"no linear association,\" we will simulate new datasets where the **slope coefficient is zero** (no linear relationship). Specifically, we will generate data based on the following model:\n",
    "\n",
    "\\text{duration} = 1.65 + 0 \\times \\text{waiting} + \\epsilon\n",
    "\n",
    "where \\(\\epsilon\\) is random noise drawn from a normal distribution with mean 0 and standard deviation 0.37.\n",
    "\n",
    "Here is the code to simulate such data, fit the models, and visualize the results:\n",
    "\n",
    "```python\n",
    "# Simulate data under the null hypothesis\n",
    "num_simulations = 1000  # Number of simulations\n",
    "simulated_slope_coefficients = []\n",
    "\n",
    "# Run the simulations\n",
    "for _ in range(num_simulations):\n",
    "    # Create a copy of the long wait times dataset\n",
    "    old_faithful_simulation = old_faithful[long_wait].copy()\n",
    "    \n",
    "    # Simulate the 'duration' values under the null hypothesis (no linear relationship)\n",
    "    old_faithful_simulation['duration'] = 1.65 + 0 * old_faithful_simulation['waiting'] + \\\n",
    "                                           stats.norm(loc=0, scale=0.37).rvs(size=len(old_faithful_simulation))\n",
    "    \n",
    "    # Fit a linear model to the simulated data\n",
    "    model = smf.ols('duration ~ waiting', data=old_faithful_simulation).fit()\n",
    "    \n",
    "    # Collect the slope coefficient from the model\n",
    "    simulated_slope_coefficients.append(model.params[1])\n",
    "\n",
    "# Convert the list of simulated coefficients to a NumPy array\n",
    "simulated_slope_coefficients = np.array(simulated_slope_coefficients)\n",
    "\n",
    "# Create a histogram to visualize the sampling distribution under the null hypothesis\n",
    "fig = px.histogram(x=simulated_slope_coefficients, nbins=50, \n",
    "                   title='Simulated Sampling Distribution of Slope Coefficients (Null Hypothesis)',\n",
    "                   labels={'x': 'Slope Coefficient (waiting)'})\n",
    "fig.show()\n",
    "\n",
    "# Calculate the p-value based on the simulated slope coefficients\n",
    "observed_slope = smf.ols('duration ~ waiting', data=old_faithful[long_wait]).fit().params[1]\n",
    "simulated_p_value = (np.abs(simulated_slope_coefficients) >= np.abs(observed_slope)).mean()\n",
    "print(f\"Simulated p-value under the null hypothesis: {simulated_p_value}\")\n",
    "```\n",
    "\n",
    "### 3. **Reporting the Results:**\n",
    "\n",
    "- **Bootstrapped Confidence Interval:**\n",
    "  After running the bootstrapping code, we will print the **95% confidence interval** of the slope coefficients. This will give us an idea of the range within which the true slope could lie, based on the bootstrapped samples.\n",
    "\n",
    "- **Simulated p-value:**\n",
    "  The **simulated p-value** is calculated by comparing the absolute values of the simulated slope coefficients to the absolute value of the observed slope coefficient from the real data. If the simulated p-value is smaller than the typical significance threshold (e.g., 0.05), it suggests that the observed slope is unlikely under the null hypothesis.\n",
    "\n",
    "- **Comparison of Confidence Interval and p-value:**\n",
    "  You will check if the **observed slope** lies within the **95% bootstrapped confidence interval**. If the observed slope is contained within this interval, it suggests the slope is plausible under the resampling process (and thus not significantly different from zero).\n",
    "  \n",
    "  Similarly, the **simulated p-value** will provide evidence against the null hypothesis, with a small p-value (<0.05) suggesting that the observed slope is significantly different from zero under the null assumption of no linear association.\n",
    "\n",
    "### 4. **Final Interpretation:**\n",
    "\n",
    "- **If the 95% bootstrapped confidence interval contains the observed slope**, this suggests that there is **no strong evidence** to reject the null hypothesis of no linear association.\n",
    "  \n",
    "- **If the simulated p-value is small (e.g., < 0.05)**, this suggests **strong evidence against the null hypothesis**, indicating that the observed slope is unlikely to have occurred by chance under the assumption of no relationship.\n",
    "\n",
    "By running these analyses, you can assess the strength of the evidence for a linear relationship between waiting time and eruption duration for the **long wait times** subset of the Old Faithful dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be8fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Understanding the New Model with an Indicator Variable\n",
    "\n",
    "To create a model with an indicator variable for \"kind\" (representing \"short\" and \"long\" wait times), we will:\n",
    "\n",
    "- **Use a categorical variable** (`kind`) to divide the data into two groups based on the wait time length. Here, we are defining:\n",
    "  - **\"Short\"** as wait times less than **68 minutes**.\n",
    "  - **\"Long\"** as wait times **greater than or equal to 68 minutes**.\n",
    "  \n",
    "- **Indicator Variable**: We'll use the column `kind` (which indicates whether a wait time is classified as short or long) as a categorical variable in the regression model. The model will treat \"short\" as the reference group, and the coefficient for the \"long\" category will reflect the difference in the **mean** duration of eruptions for long wait times relative to short wait times.\n",
    "\n",
    "#### Key Differences in Model Specifications\n",
    "\n",
    "1. **Simple Linear Regression Model with `waiting`**:\n",
    "   - `smf.ols('duration ~ waiting', data=old_faithful)` is a **continuous** model, where the relationship between `waiting` and `duration` is modeled as a straight line. The regression estimates a single slope coefficient for the relationship between the two continuous variables.\n",
    "\n",
    "2. **Subset Models (Short and Long Wait Times)**:\n",
    "   - `smf.ols('duration ~ waiting', data=old_faithful[short_wait])` and `smf.ols('duration ~ waiting', data=old_faithful[long_wait])` each fit a simple linear regression **within each group** (\"short\" and \"long\"). These models allow us to examine the slope for the `waiting` variable in each group separately.\n",
    "   - These models do not explicitly test for differences between the groups but fit separate lines for the two groups. The \"short\" and \"long\" groups are treated as having independent relationships between wait times and eruption durations.\n",
    "\n",
    "3. **Model with Indicator Variable (`kind`)**:\n",
    "   - `smf.ols('duration ~ C(kind, Treatment(reference=\"short\"))', data=old_faithful)` uses the **indicator variable** (`C(kind)`) to test whether there is a significant difference in the **mean eruption duration** between \"short\" and \"long\" wait times. This model is a **group comparison model**, where the coefficient for \"long\" represents the difference in the mean duration between the two groups.\n",
    "   \n",
    "#### Model Explanation with Indicator Variable\n",
    "\n",
    "The **\"Treatment\" coding** is used in `C(kind, Treatment(reference=\"short\"))`, which specifies that \"short\" is the **reference group**, and the regression will estimate how much **more** (or **less**) the eruption duration is for the \"long\" group relative to the \"short\" group.\n",
    "\n",
    "- The model will be of the form:\n",
    "  \n",
    "  \\text{duration} = \\beta_0 + \\beta_1 \\cdot \\text{long} + \\epsilon\n",
    "\n",
    "  where:\n",
    "  - \\(\\beta_0\\) is the **mean duration** for the \"short\" wait times (the reference group).\n",
    "  - \\(\\beta_1\\) is the **difference in the mean duration** between the \"long\" group and the \"short\" group. If \\(\\beta_1 > 0\\), this suggests that eruptions for long wait times tend to last longer than those for short wait times.\n",
    "\n",
    "### Hypothesis Test for \"No Difference Between Groups\"\n",
    "\n",
    "We can test the null hypothesis that there is **no difference** in the mean duration between the \"short\" and \"long\" groups, which corresponds to the null hypothesis \\(H_0: \\beta_1 = 0\\) in the model. This can be evaluated using the **p-value** associated with \\(\\beta_1\\).\n",
    "\n",
    "#### Code for Model with Indicator Variable\n",
    "\n",
    "```python\n",
    "import statsmodels.formula.api as smf\n",
    "import plotly.express as px\n",
    "from IPython.display import display\n",
    "\n",
    "# Create the model with an indicator variable for 'kind'\n",
    "model = smf.ols('duration ~ C(kind, Treatment(reference=\"short\"))', data=old_faithful).fit()\n",
    "\n",
    "# Display the model summary\n",
    "display(model.summary().tables[1])\n",
    "\n",
    "# Visualize the difference in eruption durations between 'short' and 'long' wait times\n",
    "fig = px.box(old_faithful, x='kind', y='duration', \n",
    "             title='Boxplot of Duration by Kind (Short vs Long Wait Times)',\n",
    "             category_orders={'kind': ['short', 'long']})\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "### Expected Output from the Code\n",
    "\n",
    "1. **Model Summary (`model.summary().tables[1]`)**: \n",
    "   - The output will show the estimated coefficients for the model, including the intercept (`β0`) for the \"short\" category and the coefficient for the \"long\" category (`β1`).\n",
    "   - The p-value associated with \\( \\beta_1 \\) will indicate whether the difference in means between \"short\" and \"long\" is statistically significant.\n",
    "\n",
    "2. **Boxplot Visualization**: \n",
    "   - The boxplot will show the distribution of the eruption durations for the \"short\" and \"long\" groups. The visual comparison will allow us to see if there is a noticeable difference in the median durations between the two groups.\n",
    "\n",
    "### Interpretation of Results\n",
    "\n",
    "- **If the p-value for \\(\\beta_1\\) is very small** (e.g., < 0.05), we have **strong evidence against the null hypothesis**, suggesting that there is a statistically significant difference between the \"short\" and \"long\" wait times.\n",
    "- **If the p-value is large** (e.g., > 0.05), we **fail to reject the null hypothesis**, indicating that there is no strong evidence to suggest a difference in eruption duration between the two groups.\n",
    "\n",
    "#### Example Interpretation Based on Hypothetical Output\n",
    "\n",
    "- Suppose the coefficient for the \"long\" category is \\( \\beta_1 = 5.2 \\), with a p-value of 0.003. This would indicate that **eruptions for long wait times are on average 5.2 minutes longer** than for short wait times, and the difference is **statistically significant** (since the p-value is less than 0.05).\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The key difference between the models using an indicator variable (`kind`) and the earlier models is that the indicator variable model explicitly tests for the **difference** in the average eruption duration between \"short\" and \"long\" wait times, using a categorical variable to divide the data. This allows us to directly address the question of whether there is a systematic difference between the two categories, rather than simply examining the relationship between waiting time and eruption duration for each subset separately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b6b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Diagnosing the Normality of Error Terms Using Residual Histograms\n",
    "\n",
    "In the context of Simple Linear Regression, one of the key assumptions is that the **error terms** (or residuals) are **normally distributed**. This assumption can be assessed by examining the shape of the residuals' distribution, typically through **histograms** and by comparing the empirical distribution of the residuals to the theoretical normal distribution.\n",
    "\n",
    "Below is an analysis of the histograms from each model, identifying which one suggests normality and why the others do not.\n",
    "\n",
    "### Model Descriptions\n",
    "\n",
    "1. **Model 1: All Data using slope**  \n",
    "   This model uses the full dataset, with a linear regression on the relationship between `duration` and `waiting` time.\n",
    "\n",
    "2. **Model 2: Short Wait Data**  \n",
    "   This model uses only the subset of data where the wait time is short (less than 68 minutes) and models the relationship between `duration` and `waiting` time.\n",
    "\n",
    "3. **Model 3: Long Wait Data**  \n",
    "   This model uses the subset of data where the wait time is long (greater than 68 minutes) and models the relationship between `duration` and `waiting` time.\n",
    "\n",
    "4. **Model 4: All Data using indicator**  \n",
    "   This model uses the full dataset with the categorical `kind` (short vs. long wait times) as a factor in the regression model to explain `duration`.\n",
    "\n",
    "### Evaluating the Histograms\n",
    "\n",
    "Each of the residual histograms will be compared to the **normal distribution curve** that has the same standard deviation as the residuals. The closer the histogram is to a bell-shaped curve, the more plausible the assumption that the residuals are normally distributed.\n",
    "\n",
    "#### 1. **Model 1: All Data using slope**\n",
    "\n",
    "- **Expected Behavior**: The residuals should roughly follow a normal distribution with a symmetric, bell-shaped histogram. This would suggest that the assumption of normality holds.\n",
    "  \n",
    "- **Interpretation**: If the histogram from Model 1 has a roughly symmetric shape around 0 and aligns reasonably well with the overlaid normal distribution curve (the dashed black line), this would suggest that the residuals are approximately normally distributed.\n",
    "\n",
    "#### 2. **Model 2: Short Wait Data**\n",
    "\n",
    "- **Expected Behavior**: For this subset, the residuals should also approximate a normal distribution if the assumption of normality is valid.\n",
    "\n",
    "- **Interpretation**: If the histogram for Model 2 shows significant skewness or heavy tails (such as a longer tail on one side of the distribution), then this would suggest that the residuals **do not follow a normal distribution**. Such skewness might arise if the relationship between `waiting` and `duration` in the short-wait subset is more complex or involves outliers that affect the residuals.\n",
    "\n",
    "#### 3. **Model 3: Long Wait Data**\n",
    "\n",
    "- **Expected Behavior**: Similar to Model 2, the residuals from the long-wait data should form a roughly normal distribution if the normality assumption holds.\n",
    "\n",
    "- **Interpretation**: If the histogram for Model 3 exhibits significant deviation from normality (e.g., skewness or multimodality), then this would suggest that the residuals are not normally distributed. For example, if there is a sharp peak or a fat tail, this would indicate potential problems with the model's assumptions.\n",
    "\n",
    "#### 4. **Model 4: All Data using indicator**\n",
    "\n",
    "- **Expected Behavior**: Since this model uses an indicator variable (`kind`), it might introduce more complexity into the residuals. The residuals could show different characteristics compared to the previous models, especially if the difference between \"short\" and \"long\" groups is large.\n",
    "\n",
    "- **Interpretation**: If the histogram for Model 4 shows a **bimodal distribution** or shows clear departure from normality (e.g., multimodal or skewed), this could suggest that the indicator variable (\"kind\") does not fully capture the variability in `duration`, and there might be additional factors influencing the residuals that aren't accounted for.\n",
    "\n",
    "### Summary and Explanation\n",
    "\n",
    "- **The model whose residual histogram best supports the assumption of normality** is likely to be **Model 1: All Data using slope**, especially if its residuals form a bell-shaped curve that closely follows the normal distribution.\n",
    "- **Models 2 and 3** might show deviations from normality due to the smaller subsets and potential complexities in the relationships for short and long wait times.\n",
    "- **Model 4** is most likely to show significant deviations from normality because of the use of the indicator variable, which could introduce additional structure into the residuals.\n",
    "\n",
    "### Key Indicators of Non-Normality\n",
    "1. **Skewness**: If the histogram shows a noticeable skew (left or right), this indicates a departure from normality.\n",
    "2. **Kurtosis (Heavy Tails)**: If the histogram has fat tails or a peaked shape, this suggests that the residuals are not normally distributed.\n",
    "3. **Multimodality**: If the histogram shows multiple peaks (bimodal or multimodal), this indicates that the residuals are not coming from a single normal distribution.\n",
    "\n",
    "### Code to Visualize and Diagnose\n",
    "\n",
    "The code provided visualizes the histograms of residuals for all four models and overlays a normal distribution curve for comparison. By examining the shape of these histograms, you can assess the normality assumption visually and determine which model best supports the assumption that the error terms are normally distributed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3e318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Explanation of the Two Sampling Approaches\n",
    "\n",
    "#### (A) **Permutation Test by Shuffling Labels**\n",
    "\n",
    "A **permutation test** involves testing whether the observed difference between two groups is consistent with the null hypothesis, which assumes that the groups come from the same population (i.e., no treatment effect, no difference). The general idea is to shuffle the group labels and calculate the difference in means after each shuffle. By repeating this many times, we can create a sampling distribution of the difference in means under the null hypothesis.\n",
    "\n",
    "1. **Shuffling the labels**: We \"shuffle\" the group labels (in this case, the `kind` variable, which divides the data into \"short\" and \"long\" wait times) and reassign them randomly to the data points. This creates new groupings where the original relationship between the group (short/long wait) and the `duration` is disrupted.\n",
    "   \n",
    "2. **Calculating the difference**: For each shuffled version of the data, we compute the mean of `duration` for the two new shuffled groups, and then calculate the difference between these means.\n",
    "\n",
    "3. **Comparison with the observed statistic**: The observed difference in means (between \"short\" and \"long\" wait times) is then compared to the distribution of differences obtained from the permutations. If the observed difference is extreme compared to the permutation distribution, we may reject the null hypothesis.\n",
    "\n",
    "**Steps in code for the permutation test**:\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# observed difference in means\n",
    "observed_diff = old_faithful.groupby('kind')['duration'].mean().iloc[::-1].diff().values[1]\n",
    "\n",
    "# permute the 'kind' labels and calculate mean differences for each permutation\n",
    "n_permutations = 10000\n",
    "permuted_diffs = []\n",
    "\n",
    "for _ in range(n_permutations):\n",
    "    shuffled_data = old_faithful.assign(kind_shuffled=old_faithful['kind'].sample(n=len(old_faithful), replace=False).values)\n",
    "    permuted_diff = shuffled_data.groupby('kind_shuffled')['duration'].mean().iloc[::-1].diff().values[1]\n",
    "    permuted_diffs.append(permuted_diff)\n",
    "\n",
    "# calculate p-value (proportion of permuted differences more extreme than observed)\n",
    "p_value = np.mean(np.abs(permuted_diffs) >= np.abs(observed_diff))\n",
    "```\n",
    "\n",
    "- **Interpretation**: A small p-value (e.g., less than 0.05) indicates that the observed difference is unlikely under the null hypothesis, suggesting that the difference between the groups is statistically significant.\n",
    "\n",
    "\n",
    "#### (B) **Bootstrapped Confidence Interval for the Difference in Means**\n",
    "\n",
    "In a **bootstrap** approach, we repeatedly resample the data with replacement to create many bootstrap samples, and then calculate the difference in means for each of these resamples. This gives us a distribution of the difference in means that reflects the uncertainty in the population difference, allowing us to construct a confidence interval.\n",
    "\n",
    "1. **Resampling with replacement**: For each group (\"short\" and \"long\"), we generate a large number of bootstrap samples by resampling the data with replacement. This simulates drawing repeated samples from the population.\n",
    "\n",
    "2. **Calculate the difference in means**: For each bootstrap sample, calculate the mean of `duration` for the \"short\" and \"long\" groups and then compute the difference in means.\n",
    "\n",
    "3. **Confidence interval**: After collecting a large number of bootstrap resamples, we use the percentiles of the bootstrap sampling distribution (e.g., 2.5% and 97.5%) to create a 95% confidence interval for the difference in means.\n",
    "\n",
    "**Steps in code for the bootstrap approach**:\n",
    "```python\n",
    "n_bootstraps = 10000\n",
    "bootstrapped_mean_differences = []\n",
    "\n",
    "for _ in range(n_bootstraps):\n",
    "    # Resample both groups with replacement\n",
    "    resampled_data = old_faithful.groupby('kind').apply(lambda x: x.sample(n=len(x), replace=True)).reset_index(drop=True)\n",
    "    \n",
    "    # Calculate the mean difference between the two resampled groups\n",
    "    mean_diff = resampled_data.groupby('kind')['duration'].mean().iloc[::-1].diff().values[1]\n",
    "    bootstrapped_mean_differences.append(mean_diff)\n",
    "\n",
    "# Calculate the 95% confidence interval\n",
    "conf_interval = np.quantile(bootstrapped_mean_differences, [0.025, 0.975])\n",
    "```\n",
    "\n",
    "- **Interpretation**: The 95% confidence interval tells us the range of values within which we would expect the true population difference in means to lie, with 95% confidence. If this interval includes zero, we fail to reject the null hypothesis of no difference between the groups. If it excludes zero, we have evidence to reject the null hypothesis.\n",
    "\n",
    "\n",
    "### (a) **How the Two Sampling Approaches Work**\n",
    "\n",
    "- **Permutation Test**: The permutation test tests the null hypothesis by repeatedly shuffling the group labels, disrupting any existing relationship between `kind` and `duration`. This generates a distribution of mean differences under the null hypothesis (no treatment effect). The observed difference is compared against this distribution, and the p-value indicates how likely the observed difference is under the null hypothesis.\n",
    "\n",
    "- **Bootstrap Confidence Interval**: In the bootstrap method, we resample the data with replacement, simulating new data sets that reflect the original data’s variability. By calculating the difference in means across many resamples, we create an empirical distribution of differences. From this, we can compute confidence intervals to estimate the range of plausible values for the true difference in means.\n",
    "\n",
    "Both methods are non-parametric and rely on resampling, but the permutation test is specifically designed to test hypotheses, while bootstrapping is used for constructing confidence intervals.\n",
    "\n",
    "\n",
    "### (b) **Comparison and Contrast with the Indicator Variable Model Approach**\n",
    "\n",
    "The **indicator variable model** used in Question 11 treated the wait time category as a factor (short vs. long) and used a **regression model** to estimate the difference between the two categories. The model specification, `smf.ols('duration ~ C(kind, Treatment(reference=\"short\"))', data=old_faithful)`, directly models the difference between the two groups using an indicator variable for `kind`.\n",
    "\n",
    "- **Similarities**:\n",
    "  - All three methods—permutation test, bootstrap confidence interval, and the indicator variable model—aim to compare the means of two groups (short vs. long wait times).\n",
    "  - Each approach allows us to assess the evidence for a difference in means between the two groups.\n",
    "\n",
    "- **Differences**:\n",
    "  - **Permutation Test**: The permutation test directly tests the null hypothesis by comparing the observed difference to a distribution generated under the null hypothesis, making it more of a hypothesis test.\n",
    "  - **Bootstrap Confidence Interval**: The bootstrap method provides a confidence interval for the difference in means, which reflects the uncertainty in the estimate of the difference. It’s more focused on estimating the plausible range of values for the true difference rather than testing a hypothesis.\n",
    "  - **Indicator Variable Model**: The regression model treats the groups as categorical variables and estimates the difference through the regression coefficients. While this method also provides evidence for a difference, it makes additional assumptions about the relationship between the predictor (`kind`) and the response (`duration`), and it requires model fitting. Unlike the permutation and bootstrap approaches, which are non-parametric, the indicator variable model is parametric and assumes a linear relationship between the independent and dependent variables.\n",
    "\n",
    "In conclusion, while all three methods estimate the difference in means between the two groups, the **permutation test** and **bootstrap method** are non-parametric, resampling-based approaches, whereas the **indicator variable model** is parametric and assumes a specific form for the data (linear relationship)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4495f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
